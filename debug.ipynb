{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.nlp import TextDataset\n",
    "from transformers import AutoTokenizer\n",
    "from toolkit.enums import Split\n",
    "from toolkit.nlp import NLPTrainingConfig\n",
    "from load_data_fn import load_data_fn\n",
    "\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"pretrained_models/baichuan2-13b-chat\", trust_remote_code=True)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    print(f\"Adding pad token {DEFAULT_PAD_TOKEN}\")\n",
    "    tokenizer.add_special_tokens(dict(pad_token=DEFAULT_PAD_TOKEN))\n",
    "\n",
    "train_dataset = TextDataset.from_file(\n",
    "    \"data/hot_finetune_data/train.json\",\n",
    "    tokenizer,\n",
    "    split=Split.TRAINING,\n",
    "    configs=NLPTrainingConfig(train_batch_size=64),\n",
    "    load_data_fn=load_data_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tokenizer.decode(train_dataset[0]['model_input']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0]['labels'])\n",
    "print(tokenizer.decode(abs(train_dataset[0]['labels']), skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"你好呀</s>\", add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32*0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(-2.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import deepspeed\n",
    "import hjson\n",
    "import numpy as np\n",
    "import toolkit\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from fire import Fire\n",
    "from toolkit import getLogger\n",
    "from toolkit.enums import Split\n",
    "from toolkit.metric import MetricDict\n",
    "from toolkit.nlp import TextDataset\n",
    "from toolkit.training import Trainer, initialize\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    PreTrainedTokenizer,\n",
    "    CONFIG_MAPPING,\n",
    ")\n",
    "from myconfig import MyTrainingConfig\n",
    "from load_data_fn import load_data_fn\n",
    "from toolkit.training.dataloader import get_dataloader\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "local_rank=0\n",
    "logger = getLogger(__name__, \"/dev/null\")\n",
    "config = MyTrainingConfig(parallel_mode=\"deepspeed\" ,\n",
    "    deepspeed_config =\"./ds_zero3_offload_mod.hjson\" ,\n",
    "    dashboard =\"tensorboard\" ,\n",
    "    model_dir =\"./baichuan-13b-chat\" ,\n",
    "    train_file_path =\"./data/hot_finetune_data/train.json\" ,\n",
    "    train_batch_size =8 ,\n",
    "    gradient_accumulation_steps =1 ,\n",
    "    seed =0 ,\n",
    "    fp16 =True ,\n",
    "    epochs =16 ,\n",
    "    opt_lr =\"1e-4\" ,\n",
    "    sch_warmup_ratio_steps =0.03 ,\n",
    "    opt_weight_decay =0 ,\n",
    "    ddp_timeout =30000 ,\n",
    "    torch_dtype =\"float16\" ,\n",
    "    logging_steps =1 ,\n",
    "    padding_side =\"left\" ,)\n",
    "\n",
    "def load_tokenizer() -> PreTrainedTokenizer:\n",
    "    # * Load tokenizer\n",
    "    tokenizer_kwargs = {\n",
    "        \"cache_dir\": config.cache_dir,\n",
    "        \"use_fast\": config.use_fast_tokenizer,\n",
    "        \"revision\": config.model_revision,\n",
    "        \"use_auth_token\": True if config.use_auth_token else None,\n",
    "    }\n",
    "    if config.model_dir:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            config.model_dir, **tokenizer_kwargs, trust_remote_code=True\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"\n",
    "            \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
    "        )\n",
    "    # * resize embedding\n",
    "    if tokenizer.pad_token is None:\n",
    "        print(f\"Adding pad token {DEFAULT_PAD_TOKEN}\")\n",
    "        tokenizer.add_special_tokens(dict(pad_token=DEFAULT_PAD_TOKEN))\n",
    "    logger.info(f\"len(tokenizer):{len(tokenizer)}\")\n",
    "    if dist.is_initialized():\n",
    "        dist.barrier()\n",
    "    return tokenizer\n",
    "\n",
    "def load_dataset(tokenizer: PreTrainedTokenizer) -> tuple:\n",
    "    # * Load training data, development data and test data\n",
    "    train_dataset = TextDataset.from_file(\n",
    "        config.train_file_path,\n",
    "        tokenizer,\n",
    "        split=Split.TRAINING,\n",
    "        configs=config,\n",
    "        load_data_fn=load_data_fn,\n",
    "    )\n",
    "    try:\n",
    "        val_dataset = TextDataset.from_file(\n",
    "            config.val_file_path,\n",
    "            tokenizer,\n",
    "            split=Split.VALIDATION,\n",
    "            configs=config,\n",
    "            load_data_fn=load_data_fn,\n",
    "        )\n",
    "    except TypeError as e:\n",
    "        if local_rank == 0:\n",
    "            logger.warning(e)\n",
    "        val_dataset = None\n",
    "    try:\n",
    "        test_dataset = TextDataset.from_file(\n",
    "            config.test_file_path,\n",
    "            tokenizer,\n",
    "            split=Split.TEST,\n",
    "            configs=config,\n",
    "            load_data_fn=load_data_fn,\n",
    "        )\n",
    "    except TypeError as e:\n",
    "        if local_rank == 0:\n",
    "            logger.warning(e)\n",
    "        test_dataset = None\n",
    "    if dist.is_initialized():\n",
    "        dist.barrier()\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "def load_model(tokenizer) -> deepspeed.DeepSpeedEngine:\n",
    "    start = time.time()\n",
    "    # * Load model config\n",
    "    model_kwargs = {\n",
    "        \"cache_dir\": config.cache_dir,\n",
    "        \"revision\": config.model_revision,\n",
    "        \"use_auth_token\": True if config.use_auth_token else None,\n",
    "    }\n",
    "    if config.model_dir:\n",
    "        model_config = AutoConfig.from_pretrained(\n",
    "            config.model_dir, **model_kwargs, trust_remote_code=True\n",
    "        )\n",
    "    else:\n",
    "        model_config = CONFIG_MAPPING[config.model_type]()\n",
    "        logger.warning(\"You are instantiating a new config instance from scratch.\")\n",
    "        if config.config_overrides is not None:\n",
    "            logger.info(f\"Overriding config: {config.config_overrides}\")\n",
    "            model_config.update_from_string(config.config_overrides)\n",
    "            logger.info(f\"New config: {config}\")\n",
    "    # * Load model\n",
    "    logger.debug(f\"local_rank {local_rank}: Loading model ...\")\n",
    "    if config.model_dir:\n",
    "        torch_dtype = (\n",
    "            config.torch_dtype\n",
    "            if config.torch_dtype in [\"auto\", None]\n",
    "            else getattr(torch, config.torch_dtype)\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.model_dir,\n",
    "            from_tf=bool(\".ckpt\" in config.model_dir),\n",
    "            config=model_config,\n",
    "            cache_dir=config.cache_dir,\n",
    "            revision=config.model_revision,\n",
    "            use_auth_token=True if config.use_auth_token else None,\n",
    "            torch_dtype=torch_dtype,\n",
    "            low_cpu_mem_usage=False,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_config(config)\n",
    "        n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n",
    "        logger.info(\n",
    "            f\"Training new model from scratch - Total size={n_params/2**20:.2f}M params\"\n",
    "        )\n",
    "    embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "    if len(tokenizer) != embedding_size:\n",
    "        logger.info(\"resize the embedding size by the size of the tokenizer\")\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    ds_model=model\n",
    "    # if config.parallel_mode == \"deepspeed\":\n",
    "    #     deepspeed_config = hjson.load(open(config.deepspeed_config, \"r\"))\n",
    "    #     config.set_deepspeed(deepspeed_config)\n",
    "    #     ds_model, _, _, _ = deepspeed.initialize(model=model, config=deepspeed_config)\n",
    "    end = time.time()\n",
    "    logger.debug(f\"local_rank {local_rank}: Loading model takes {end - start:.2f} sec.\")\n",
    "    return ds_model\n",
    "\n",
    "# * Loading tokenizer\n",
    "tokenizer = load_tokenizer()\n",
    "\n",
    "# * load dataset\n",
    "dataset_train, val_dataset, test_dataset = load_dataset(tokenizer)\n",
    "\n",
    "# *load model\n",
    "model = load_model(tokenizer)\n",
    "\n",
    "dataloader_train, sampler = get_dataloader(\n",
    "            dataset_train, config, Split.TRAINING, collate_fn=dataset_train.collate_fn, shuffle=config.shuffle\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader_train:\n",
    "    output = model(**batch, max_new_tokens=20)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/codes/train_llms/ngram.py:31: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  EN_PART_RE = re.compile(\"[\\s\\u0021-\\u007f]+\")\n",
      "WARNING:root:building dataset...\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from build_dataset import MyDataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "tokenizer =  AutoTokenizer.from_pretrained(\"pretrained_models/baichuan2-13b-chat\", trust_remote_code=True)\n",
    "path = Path(\"data/hot_finetune_data/\")\n",
    "files = [os.path.join(path,file.name) for file in path.glob(\"*.json\")]\n",
    "dataset = MyDataset(files, tokenizer, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.training import get_dataloader\n",
    "from toolkit.enums import Split\n",
    "from toolkit.nlp import NLPTrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, _ = get_dataloader(dataset, NLPTrainingConfig(train_batch_size=8), Split.TRAINING, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed import DeepSpeedConfig\n",
    "ds_config = {\n",
    "    \"fp16\": {\n",
    "        \"enabled\": False\n",
    "    },\n",
    "    \"bf16\": {\n",
    "        \"enabled\": False\n",
    "    },\n",
    "    \"train_batch_size\":2\n",
    "}\n",
    "config = DeepSpeedConfig(ds_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_json('data/hot_finetune_data/train_v6.json', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = df.sample(100, replace=False)\n",
    "train = df.drop(dev.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 127 to 5129\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  100 non-null    object\n",
      " 1   input        100 non-null    object\n",
      " 2   output       100 non-null    object\n",
      " 3   query        71 non-null     object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5962 entries, 0 to 6061\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  5962 non-null   object\n",
      " 1   input        5962 non-null   object\n",
      " 2   output       5962 non-null   object\n",
      " 3   query        3890 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 232.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6062 entries, 0 to 6061\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  6062 non-null   object\n",
      " 1   input        6062 non-null   object\n",
      " 2   output       6062 non-null   object\n",
      " 3   query        3961 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 189.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dev.info()\n",
    "train.info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'data/hot_finetune_data'\n",
    "from pathlib import Path\n",
    "\n",
    "d = Path(d)\n",
    "\n",
    "train_dir = d/'train'\n",
    "dev_dir = d/'dev'\n",
    "\n",
    "train_dir.mkdir(exist_ok=True)\n",
    "dev_dir.mkdir(exist_ok=True)\n",
    "\n",
    "train.to_json(train_dir/\"all.json\", orient=\"records\", lines=True, force_ascii=False)\n",
    "dev.to_json(dev_dir/\"all.json\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125696\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "import torch\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"./pretrained_models/baichuan2-13b-chat/\", trust_remote_code=True)\n",
    "print(config.vocab_size)\n",
    "\n",
    "torch_dtype = torch.float16\n",
    "from_pretrained_kwargs = dict(\n",
    "    from_tf=False,\n",
    "    cache_dir=None,\n",
    "    revision=\"main\",\n",
    "    use_auth_token=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=False,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python3.11.2/lib/python3.11/site-packages/torchmetrics/utilities/imports.py:24: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _PYTHON_LOWER_3_8 = LooseVersion(_PYTHON_VERSION) < LooseVersion(\"3.8\")\n",
      "/root/codes/train_llms/toolkit_pkg/toolkit/metric/metric_base.py:102: DeprecationWarning: invalid escape sequence '\\i'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b4e689edb446218e8917fa7b0f7745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'rougeL': 0.6333333452542623, 'rouge2': 0.3055555621782939}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolkit.metric import rouge\n",
    "\n",
    "pred = [\"你好吗\", \"你多大\", \"abcdefg\"]\n",
    "tgt=[\"好吗\", \"你\", \"bfg\"]\n",
    "\n",
    "rouge(pred, tgt, ('rougeL', 'rouge2'), 'zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44361116955724544\n",
      "0.7455188513831694\n"
     ]
    }
   ],
   "source": [
    "from toolkit.metric import distinct_n_corpus_level\n",
    "sentences = [\n",
    "            'the cat sat on the mat'.split(),\n",
    "            'mat the on sat cat the'.split(),\n",
    "            'i do not know'.split(),\n",
    "            'Sorry but i do not know'.split(),\n",
    "        ]\n",
    "sentences = [\n",
    "            list('徐怀钰近期参加综艺节目《乘风》复出，享受舞台找回自我。\\n徐怀钰的经历充满波折，家庭贫困、爷爷的心理问题，这些年一直在努力付出。虽然在《乘风》的舞台上复出效果不理想，但我们也看到了徐怀钰逐渐找回自我，这比比赛的输赢更重要。在《乘风》中，她与秋瓷炫、黄丽玲等人成为了好友，并携手合作。虽然她没有王心凌的机遇，但《乘风》也为她提供了一个重要的机会。她因一公被抨击而感到难过，好在有Ella等人的安慰与支持，让她挺过了难关。五公时，慢热的徐怀钰终于找到了感觉，秋瓷炫也为她的变化感到高兴，看出她开始享受舞台了。这次，徐怀钰主动和黄丽玲合作，无疑将带来许多火花。\\n作为徐怀钰复出的舞台，《乘风》让徐怀钰找回终于找回了自我。让我们一起期待徐怀钰更多精彩表现！'),\n",
    "            list('上周全国食用农产品和生产资料价格小幅上涨，其中食用农产品市场价格上涨1.6%，生产资料市场价格上涨0.1%。\\n粮油批发价格略有波动，大米、豆油和菜籽油价格下降，花生油价格上涨，面粉价格持平。30种蔬菜平均批发价格上涨0.4%，其中黄瓜、生菜和菠菜价格大幅上涨。6种水果平均批发价格小幅下降，西瓜、葡萄和梨价格下降最多。肉类价格小幅波动，牛肉和羊肉价格下降，猪肉价格上涨。禽产品价格小幅上涨，鸡蛋和白条鸡价格上涨。水产品批发价格以降为主，鲤鱼、鲢鱼和草鱼价格下降。\\n价格的小幅上涨对我们的生活会带来一定的影响。你会因为上涨的食用农产品价格而改变自己的购买选择吗？还是会选择继续购买自己喜欢的食物？留言和我分享你的想法！\\n')\n",
    "        ]\n",
    "print(distinct_n_corpus_level(sentences, 1))\n",
    "print(distinct_n_corpus_level(sentences, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7598)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.functional.text import bleu_score\n",
    "preds = ['the cat is on the mat']\n",
    "target = ['there is a cat on the mat']\n",
    "print(bleu_score(preds, target, 4))\n",
    "\n",
    "preds = ['the cat is on the mat']\n",
    "target = ['a cat is on the mat']\n",
    "bleu_score(preds, target, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7054014374088451,\n",
       " 0.4887164517296948,\n",
       " 0.36973494931036327,\n",
       " 0.19433094436376075]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "preds = 'the cat is on the mat'.split()\n",
    "target = ['there is a cat on the mat'.split()]\n",
    "chencherry = SmoothingFunction()\n",
    "sentence_bleu(target, preds, [(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)],smoothing_function=chencherry.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8333333333333334, 0.816496580927726, 0.7937005259840998, 0.7598356856515925]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = 'the cat is on the mat'.split()\n",
    "target = ['a cat is on the mat'.split()]\n",
    "chencherry = SmoothingFunction()\n",
    "sentence_bleu(target, preds, [(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)],smoothing_function=chencherry.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5882352941176471,\n",
       " 0.5601120336112039,\n",
       " 0.5251127559361087,\n",
       " 0.47902287469880817]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "preds = ['the cat is on the mat'.split(), 'If there is no ngrams overlap for any order of n-grams'.split()]\n",
    "target = [['a cat is on the mat'.split()], ['for any order of n-grams'.split()]]\n",
    "chencherry = SmoothingFunction()\n",
    "corpus_bleu(target, preds, [(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)],smoothing_function=chencherry.method1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47902287469880817"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu(target, preds,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24430698313673305\n",
      "0.9138773566669056\n"
     ]
    }
   ],
   "source": [
    "from toolkit.metric import self_bleu_one_set\n",
    "\n",
    "print(self_bleu_one_set(['the cat is on the mat', 'a cat is on the mat', 'there is a cat on the mat']))\n",
    "print(self_bleu_one_set(['the cat is on the mat', 'a dog is running', 'birds can fly in sky freely']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16604713 0.16716345 0.20166345 0.24430698]\n",
      "[0.56541006 0.73415542 0.85089009 0.91387736]\n"
     ]
    }
   ],
   "source": [
    "from toolkit.metric import self_bleu_one_set\n",
    "\n",
    "print(self_bleu_one_set(['the cat is on the mat', 'a cat is on the mat', 'there is a cat on the mat'], weights=[(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)]))\n",
    "print(self_bleu_one_set(['the cat is on the mat', 'a dog is running', 'birds can fly in sky freely'], weights=[(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5790921699018193"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolkit.metric import self_bleu\n",
    "\n",
    "self_bleu([['the cat is on the mat', 'a cat is on the mat', 'there is a cat on the mat'], ['the cat is on the mat', 'a dog is running', 'birds can fly in sky freely']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3657286 , 0.45065944, 0.52627677, 0.57909217])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolkit.metric import self_bleu\n",
    "\n",
    "self_bleu([['the cat is on the mat', 'a cat is on the mat', 'there is a cat on the mat'], ['the cat is on the mat', 'a dog is running', 'birds can fly in sky freely']], weights=[(1.,), (1./2., 1./2.), (1./3., 1./3., 1./3.), (1./4., 1./4., 1./4., 1./4.)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b86acde8f1383f86f3021849fe9adf6a3ab376df7b33a306f998570f99994f92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
